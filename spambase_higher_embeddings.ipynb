{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Methods for Spam Email Detection\n",
    "\n",
    "We propose an e-mail spam filter which first embeds the e-mails in higher dimensional vector spaces then classifies them using machine learning methods. We test our filter on 'Spambase Dataset' available at [the UCI Machine Learning Repository](http://www.ics.uci.edu/~mlearn/MLRepository.html). For embedding the e-mails in higher dimensions, we use the vector representations of the words from the pretrained datasets by Word2Vec, GloVe, and FastText. For classification, we test with Logistic Regression (LogReg), Random Forest (RF), and Naive Bayes (NB) as well as some less transparent methods such as Support Vector Machines (SVM) and Multi-Layer Perceptor (MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "There are many publicly available benchmark spam datasets. In these datasets, the messages are usually kept as text like in the case of the below SMSSpamCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import glob \n",
    "import bcolz\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sms=pd.read_csv('/mypath/smsspamcollection/SMSSpamCollection.txt',sep='\\t',index_col=False,header=None,names=['Label','SMS'])\n",
    "number_of_sms=data_sms.shape[0]\n",
    "data_sms_nolabel=data_sms['SMS'] #SMS series\n",
    "label=data_sms['Label'] #Label series\n",
    "y=np.array([1 if label.iloc[i]=='spam' else 0 for i in range(number_of_sms)]) #convert the label to numeric (to be used later)\n",
    "data_sms.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or sometimes to protect privacy they are encoded like in the case of PU corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2056 118 22577 20908 14616</td>\n",
       "      <td>284 14851 80 16147 17345 14338 130 19410 47 58...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2056 118 14140 84 13147 1613 383 80 1867 1601...</td>\n",
       "      <td>284 4353 47 17011 15691 9997 18783 1613 1613 9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0                         2056 118 22577 20908 14616   \n",
       "1   2056 118 14140 84 13147 1613 383 80 1867 1601...   \n",
       "\n",
       "                                             Message Label  \n",
       "0  284 14851 80 16147 17345 14338 130 19410 47 58...     0  \n",
       "1  284 4353 47 17011 15691 9997 18783 1613 1613 9...     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pu1=pd.DataFrame(index=range(1099),columns=['Subject','Space','Message','Label'])\n",
    "for i,filename in enumerate(glob.glob('/mypath/pu_corpora_public/pu1/all_messages/*.txt')):\n",
    "\twith open(filename, 'r') as f:\n",
    "\t\tfor cnt, line in enumerate(f):\n",
    "\t\t\tdata_pu1.iloc[i][data_pu1.columns[cnt]]=line.replace('Subject:','').replace('\\n','')\n",
    "\tif re.search('legit',filename):\n",
    "\t\tdata_pu1.iloc[i]['Label'] =0\n",
    "\telse:\n",
    "\t\tdata_pu1.iloc[i]['Label'] =1\n",
    "data_pu1.drop('Space',inplace=True,axis=1)\n",
    "label_pu1=data_pu1['Label']\n",
    "subject_pu1=data_pu1['Subject']\n",
    "message_pu1=data_pu1['Message']\n",
    "data_pu1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important step in text processing is to find a numerical representation of the text. Among such methods, *Bag-of-Words* (BoW), *CountVectorizer*, and *Term frequency - Inverse document frequency* (Tf-idf) are the most common ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea behind the methods like BoW, CountVec, and TfIdf is to count, in different ways, the occurences of the words or collection of words in the corpus. For instance, in the LINES below, we count only the words which are not in the 'english' dictionnary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer(stop_words='english',ngram_range=(1,1))# initiate\n",
    "data_sms_vec=vect.fit_transform(data_sms_nolabel) #numeric sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>ú1</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 8445 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "0  0.0  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "1  0.0  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "2  0.0  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "3  0.0  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "\n",
       "   0125698789   02  ...    zindgi  zoe  zogtorius  zoom  zouk  zyada   èn  \\\n",
       "0         0.0  0.0  ...       0.0  0.0        0.0   0.0   0.0    0.0  0.0   \n",
       "1         0.0  0.0  ...       0.0  0.0        0.0   0.0   0.0    0.0  0.0   \n",
       "2         0.0  0.0  ...       0.0  0.0        0.0   0.0   0.0    0.0  0.0   \n",
       "3         0.0  0.0  ...       0.0  0.0        0.0   0.0   0.0    0.0  0.0   \n",
       "\n",
       "    ú1  〨ud  Label  \n",
       "0  0.0  0.0      0  \n",
       "1  0.0  0.0      0  \n",
       "2  0.0  0.0      1  \n",
       "3  0.0  0.0      0  \n",
       "\n",
       "[4 rows x 8445 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sms_vec.shape\n",
    "features_vect=np.array(vect.get_feature_names())\n",
    "data_sms_frame=pd.DataFrame(np.array(data_sms_vec.todense()),columns=features_vect)\n",
    "data_sms_frame=data_sms_frame.join(pd.DataFrame({'Label':y}))\n",
    "data_sms_frame.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a numeric representation of the 5572 messages in terms of 8712 attributes determined by the default settings of the vectorizer TfidfVectorizer(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "In this notebook, we work with the Spambase dataset. Our motivation is to test whether novel techniques in Natural Language Processing (NLP) such as *Word2Vec*, *GloVe*, and *FastText* can improve classifying e-mails where the corpus is not known. The e-mails are represented by the frequency information of the pre-selected 57 attributes and an  attribute for the class the e-mail (1=spam, 0=non_spam). Let us have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>address</th>\n",
       "      <th>all</th>\n",
       "      <th>3d</th>\n",
       "      <th>our</th>\n",
       "      <th>over</th>\n",
       "      <th>remove</th>\n",
       "      <th>internet</th>\n",
       "      <th>order</th>\n",
       "      <th>mail</th>\n",
       "      <th>...</th>\n",
       "      <th>;</th>\n",
       "      <th>(</th>\n",
       "      <th>[</th>\n",
       "      <th>!</th>\n",
       "      <th>$</th>\n",
       "      <th>#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longes</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   make  address   all   3d   our  over  remove  internet  order  mail  ...    \\\n",
       "0  0.00     0.64  0.64  0.0  0.32  0.00    0.00      0.00   0.00  0.00  ...     \n",
       "1  0.21     0.28  0.50  0.0  0.14  0.28    0.21      0.07   0.00  0.94  ...     \n",
       "2  0.06     0.00  0.71  0.0  1.23  0.19    0.19      0.12   0.64  0.25  ...     \n",
       "3  0.00     0.00  0.00  0.0  0.63  0.00    0.31      0.63   0.31  0.63  ...     \n",
       "4  0.00     0.00  0.00  0.0  0.63  0.00    0.31      0.63   0.31  0.63  ...     \n",
       "\n",
       "      ;      (    [      !      $      #  capital_run_length_average  \\\n",
       "0  0.00  0.000  0.0  0.778  0.000  0.000                       3.756   \n",
       "1  0.00  0.132  0.0  0.372  0.180  0.048                       5.114   \n",
       "2  0.01  0.143  0.0  0.276  0.184  0.010                       9.821   \n",
       "3  0.00  0.137  0.0  0.137  0.000  0.000                       3.537   \n",
       "4  0.00  0.135  0.0  0.135  0.000  0.000                       3.537   \n",
       "\n",
       "   capital_run_length_longes  capital_run_length_total  Label  \n",
       "0                         61                       278      1  \n",
       "1                        101                      1028      1  \n",
       "2                        485                      2259      1  \n",
       "3                         40                       191      1  \n",
       "4                         40                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "#load the data as an array\n",
    "data=np.genfromtxt('/mypath/spambase/spambase.txt',delimiter=',')\n",
    "labels=data[:,-1]\n",
    "data_nolabel=np.delete(data,57,axis=1)\n",
    "#as as a dataframe a more presentable form\n",
    "col_names=list(['make','address','all','3d','our','over','remove','internet','order','mail','receive','will','people','report','addresses','free','business','email','you','credit','your','font','000','money','hp','hpl','george','650','lab','labs','telnet','857','data','415','85','technology','1999','parts','pm','direct','cs','meeting','original','project','re','edu','table','conference',';','(','[','!','$','#','capital_run_length_average', 'capital_run_length_longes', 'capital_run_length_total','Label'])\n",
    "data_df=pd.read_csv('/mypath/spambase/spambase.txt',index_col=False,names=col_names) \n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate 30% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data,train_label,test_label=train_test_split(data_nolabel,labels,train_size=0.7,test_size=0.3,random_state=1654)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any model that we build will be an achievement if its accuracy is greater than the null accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Non-Spam': 0.6046343229543809, 'Spam': 0.3953656770456191}\n"
     ]
    }
   ],
   "source": [
    "null_model={'Non-Spam':1-test_label.mean(),'Spam':test_label.mean()}\n",
    "print(null_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this corpus is already in numerical form, we can train our first classifiers right away. We try 5 different types of classifiers: Logistic Regression, Linear Discriminant Analysis (LDA), Support Vector Machines (SVM), Boosted Tree, Random Forest, and Nearest Neighborhood. As our purpose is not the atteint the highest accuracy, we will not go into the parameter search and use all methods with their default settings in scikit-learn.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9290369297610427\n",
      "TN: 793 FP: 42 FN: 56 TP: 490\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (92.90%)\n",
    "logreg=LogisticRegression(random_state=55973,solver='liblinear')\n",
    "logreg.fit(train_data,train_label)\n",
    "test_pred=logreg.predict(test_data)\n",
    "print('Acc:',logreg.score(test_data,test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(test_label,test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9601737871107893\n",
      "TN: 817 FP: 18 FN: 37 TP: 509\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (96.02%)\n",
    "rf=RandomForestClassifier(random_state=55973,n_estimators=10)\n",
    "rf.fit(train_data,train_label)\n",
    "test_pred=rf.predict(test_data)\n",
    "print('Acc:',rf.score(test_data,test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(test_label,test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.834902244750181\n",
      "TN: 704 FP: 131 FN: 97 TP: 449\n"
     ]
    }
   ],
   "source": [
    "# SVM (83.49%)\n",
    "svm=SVC(random_state=55973,gamma='auto')\n",
    "svm.fit(train_data,train_label)\n",
    "test_pred=svm.predict(test_data)\n",
    "print('Acc:',svm.score(test_data,test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(test_label,test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9167270094134685\n",
      "TN: 772 FP: 63 FN: 52 TP: 494\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree (91.67%)\n",
    "tree=DecisionTreeClassifier(random_state=55973)\n",
    "tree.fit(train_data,train_label)\n",
    "test_pred=tree.predict(test_data)\n",
    "print('Acc:',tree.score(test_data,test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(test_label,test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8957277335264301\n",
      "TN: 798 FP: 37 FN: 107 TP: 439\n"
     ]
    }
   ],
   "source": [
    "# LDA (89.57%)\n",
    "lda=LinearDiscriminantAnalysis()\n",
    "lda.fit(train_data,train_label)\n",
    "test_pred=lda.predict(test_data)\n",
    "print('Acc:',lda.score(test_data,test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(test_label,test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.7950760318609703\n",
      "TN: 708 FP: 127 FN: 156 TP: 390\n"
     ]
    }
   ],
   "source": [
    "# KNN (79.51%)\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(train_data,train_label)\n",
    "test_pred=knn.predict(test_data)\n",
    "print('Acc:',knn.score(test_data,test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(test_label,test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pretrained Methods\n",
    "Using pretrained datasets for *Word2Vec*, *GloVe*, and *FastText*, we embed the Spambase dataset to a higher dimension.  First of all, from the pretrained dataset, we choose the $d$-dimensional attribute (column) vectors ${v_1, . . . , v_{57}}$ that represent the 57 attributes of the dataset. Next, we find a vector representation of the e-mails by doing a weighted summation of the attribute vectors with weights being the frequencies. That is, for all $i=1,\\dots,4601$, $e_i =F(i,1)v_1 +...+F(i,n)v_n$ where $F=[F(i,j)]_{1\\leq i \\leq 4601,1\\leq j \\leq 57}$ is the dataset with labels(last column) removed. Finally, we arrange the vectors $e_i$ in the rows of the matrix $E = [e_1^T , \\dots, e_m^T]$ of type $4601 \\times d$. The matrix $E$ is the embedding of the e-mail corpus represented by the matrix $F$ to $d$ dimensions. Once the dataset is embedded into dimension $d$, we can train classifiers. One challenge that we might face during the above procedure is that some of the attributes might not have a corresponding vector in the used pretrained dataset. We will see how to handle these situations once we face them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Pretrained Dataset\n",
    "We fisrt try Googlenews pretrained word2vec 300 dimensional vectors ([1]) to embed our the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load word2vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "w2v_words = gensim.models.KeyedVectors.load_word2vec_format(('/mypath/word2Vec/GoogleNews-vectors-negative300.bin'), binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded vectors can be seen with the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_words['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe right away  that the words '000', 'hpl', '650', '857', '415', '85', '1999' do not have corresponding vectors. However all the characters in those missing words have. So we construct a vector for everyone of those missing words by adding the vectors that represent the characters in that word. For instance, for the word 'hpl', we add the vectors of the letters 'h', 'p', and 'l'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word23_000=3*w2v_words['0']\n",
    "word26_hpl=w2v_words['h']+w2v_words['p']+w2v_words['l']\n",
    "word28_650=w2v_words['6']+w2v_words['5']+w2v_words['0']\n",
    "word32_857=w2v_words['8']+w2v_words['5']+w2v_words['7']\n",
    "word34_415=w2v_words['4']+w2v_words['1']+w2v_words['5']\n",
    "word35_85=w2v_words['8']+w2v_words['5']\n",
    "word37_1999=w2v_words['1']+w2v_words['9']+w2v_words['9']+w2v_words['9']+w2v_words['9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other problem that we run into is that the punctuation symbols ';','(','\\[','!' as well as the 3 attributes 'capital_run_length_average', 'capital_run_length_longes', 'capital_run_length_total' do not have vector representation. For those, we simply concatanate their frequencies to the vectors. Hence, we obtain an embedding of the dataset into dimension 307."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset is now of the form (4601, 307)\n"
     ]
    }
   ],
   "source": [
    "email_words=np.column_stack([w2v_words['make'],w2v_words['address'],w2v_words['all'],w2v_words['3d'],w2v_words['our'],w2v_words['over'],w2v_words['remove'],w2v_words['internet'],w2v_words['order'],w2v_words['mail'],w2v_words['receive'],w2v_words['will'],w2v_words['people'],w2v_words['report'],w2v_words['addresses'],w2v_words['free'],w2v_words['business'],w2v_words['email'],w2v_words['you'],w2v_words['credit'],w2v_words['your'],w2v_words['font'],word23_000,w2v_words['money'],w2v_words['hp'],word26_hpl,w2v_words['george'],word28_650,w2v_words['lab'],w2v_words['labs'],w2v_words['telnet'],word32_857,w2v_words['data'],word34_415,word35_85,w2v_words['technology'],word37_1999,w2v_words['parts'],w2v_words['pm'],w2v_words['direct'],w2v_words['cs'],w2v_words['meeting'],w2v_words['original'],w2v_words['project'],w2v_words['re'],w2v_words['edu'],w2v_words['table'],w2v_words['conference'],w2v_words['$'],w2v_words['#']])\n",
    "email_coef=np.delete(data_nolabel,[48,49,50,51,54,55,56],axis=1)\n",
    "email_concat=np.delete(data_nolabel,np.append(np.arange(48),np.append(52,53)),axis=1)\n",
    "email_body=np.zeros([4601,300])\n",
    "for i in range(4601):\n",
    "\tfor j in range(50):\n",
    "\t\temail_body[i,:]=email_body[i,:]+email_coef[i,j]*email_words[:,j]\n",
    "emails=np.append(email_body,email_concat,axis=1)\n",
    "print(\"the dataset is now of the form\",emails.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to do classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train_data,w2v_test_data,w2v_train_label,w2v_test_label=train_test_split(emails,labels,train_size=0.7,test_size=0.3,random_state=1654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9297610427226647\n",
      "TN: 792 FP: 43 FN: 54 TP: 492\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (92.98%)\n",
    "logreg_w2v=LogisticRegression(random_state=55973,solver='liblinear')\n",
    "logreg_w2v.fit(w2v_train_data,w2v_train_label)\n",
    "w2v_test_pred=logreg_w2v.predict(w2v_test_data)\n",
    "print('Acc:',logreg_w2v.score(w2v_test_data,w2v_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(w2v_test_label,w2v_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9348298334540188\n",
      "TN: 798 FP: 37 FN: 53 TP: 493\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (93.48%)\n",
    "rf_w2v=RandomForestClassifier(random_state=55973,n_estimators=10)\n",
    "rf_w2v.fit(w2v_train_data,w2v_train_label)\n",
    "w2v_test_pred=rf_w2v.predict(w2v_test_data)\n",
    "print('Acc:',rf_w2v.score(w2v_test_data,w2v_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(w2v_test_label,w2v_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8740043446777698\n",
      "TN: 728 FP: 107 FN: 67 TP: 479\n"
     ]
    }
   ],
   "source": [
    "# SVM (87.40%)\n",
    "svm_w2v=SVC(random_state=55973,gamma='auto')\n",
    "svm_w2v.fit(w2v_train_data,w2v_train_label)\n",
    "w2v_test_pred=svm_w2v.predict(w2v_test_data)\n",
    "print('Acc:',svm_w2v.score(w2v_test_data,w2v_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(w2v_test_label,w2v_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9058653149891384\n",
      "TN: 761 FP: 74 FN: 56 TP: 490\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree (90.59%)\n",
    "tree_w2v=DecisionTreeClassifier(random_state=55973)\n",
    "tree_w2v.fit(w2v_train_data,w2v_train_label)\n",
    "w2v_test_pred=tree_w2v.predict(w2v_test_data)\n",
    "print('Acc:',tree_w2v.score(w2v_test_data,w2v_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(w2v_test_label,w2v_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8957277335264301\n",
      "TN: 798 FP: 37 FN: 107 TP: 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emintatar/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# LDA (89.57%)\n",
    "lda_w2v=LinearDiscriminantAnalysis()\n",
    "lda_w2v.fit(w2v_train_data,w2v_train_label)\n",
    "w2v_test_pred=lda_w2v.predict(w2v_test_data)\n",
    "print('Acc:',lda_w2v.score(w2v_test_data,w2v_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(w2v_test_label,w2v_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the warning says the attributes are collinear. To remove colinearity, we apply PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=307)\n",
    "emails_pca=pca.fit_transform(emails)\n",
    "w2v_train_data_pca,w2v_test_data_pca,w2v_train_label_pca,w2v_test_label_pca=train_test_split(emails_pca,labels,train_size=0.7,test_size=0.3,random_state=1654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8971759594496741\n",
      "TN: 788 FP: 47 FN: 95 TP: 451\n"
     ]
    }
   ],
   "source": [
    "# LDA with PCA (89.71%)\n",
    "lda_w2v_pca=LinearDiscriminantAnalysis()\n",
    "lda_w2v_pca.fit(w2v_train_data_pca,w2v_train_label_pca)\n",
    "w2v_pca_test_pred=lda_w2v_pca.predict(w2v_test_data_pca)\n",
    "print('Acc:',lda_w2v_pca.score(w2v_test_data_pca,w2v_test_label_pca))\n",
    "tn, fp, fn, tp=confusion_matrix(w2v_test_label_pca,w2v_pca_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collinearity is removed and the accuracy improves slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8385228095582911\n",
      "TN: 719 FP: 116 FN: 107 TP: 439\n"
     ]
    }
   ],
   "source": [
    "# KNN (83.85%)\n",
    "knn_w2v=KNeighborsClassifier()\n",
    "knn_w2v.fit(w2v_train_data,w2v_train_label)\n",
    "w2v_test_pred=knn_w2v.predict(w2v_test_data)\n",
    "print('Acc:',knn_w2v.score(w2v_test_data,w2v_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(w2v_test_label,w2v_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Pretrained Dataset\n",
    "Let's try the same approch with 1.9 million 300-dimensional word vectors trained by GloVe on Common Crawl dataset.[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading Glove pretrained \n",
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir='/mypath/Glove/yukleme', mode='w')\n",
    "with open('/mypath/Glove/glove.6B.300d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)\n",
    "    \n",
    "vectors = bcolz.carray(vectors[1:].reshape((400000,300)), rootdir='/mypath/Glove/yukleme', mode='w')\n",
    "vectors.flush()\n",
    "pickle.dump(words, open('/mypath/Glove/glove.6B.300d.txt_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open('/mypath/Glove/glove.6B.300d.txt_idx.pkl', 'wb'))\n",
    "\n",
    "glove_words = {w: vectors[word2idx[w]] for w in words} # creates the dictionary with the word and its associated vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the loaded vectors with the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_words['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this pretrained dataset, all the attributes except the 3 that correpond to the capital runs have vector representation. So by concatanating these 3 attributes to the pretrained vectors, we obtain an embedding of the e-mail dataset into dimension 303."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset is now of the form (4601, 303)\n"
     ]
    }
   ],
   "source": [
    "words_in_glove=['make','address','all','3d','our','over','remove','internet','order','mail','receive','will','people','report','addresses','free','business','email','you','credit','your','font','000','money','hp','hpl','george','650','lab','labs','telnet','857','data','415','85','technology','1999','parts','pm','direct','cs','meeting','original','project','re','edu','table','conference',';','(','[','!','$','#']\n",
    "email_glove_words=np.column_stack([glove_words['make'],glove_words['address'],glove_words['all'],glove_words['3d'],glove_words['our'],glove_words['over'],glove_words['remove'],glove_words['internet'],glove_words['order'],glove_words['mail'],glove_words['receive'],glove_words['will'],glove_words['people'],glove_words['report'],glove_words['addresses'],glove_words['free'],glove_words['business'],glove_words['email'],glove_words['you'],glove_words['credit'],glove_words['your'],glove_words['font'],glove_words['000'],glove_words['money'],glove_words['hp'],glove_words['hpl'],glove_words['george'],glove_words['650'],glove_words['lab'],glove_words['labs'],glove_words['telnet'],glove_words['857'],glove_words['data'],glove_words['415'],glove_words['85'],glove_words['technology'],glove_words['1999'],glove_words['parts'],glove_words['pm'],glove_words['direct'],glove_words['cs'],glove_words['meeting'],glove_words['original'],glove_words['project'],glove_words['re'],glove_words['edu'],glove_words['table'],glove_words['conference'],glove_words[';'],glove_words['('],glove_words['['],glove_words['!'],glove_words['$'],glove_words['#']])\n",
    "email_glove_coef=np.delete(data_nolabel,[54,55,56],axis=1)\n",
    "email_glove_concat=np.delete(data_nolabel,np.arange(54),axis=1)\n",
    "email_glove_body=np.zeros([4601,300])\n",
    "for i in range(4601):\n",
    "\tfor j in range(len(words_in_glove)):\n",
    "\t\temail_glove_body[i,:]=email_glove_body[i,:]+email_glove_coef[i,j]*email_glove_words[:,j]\n",
    "glove_emails=np.append(email_glove_body,email_glove_concat,axis=1)\n",
    "print(\"the dataset is now of the form\",glove_emails.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_train_data,glove_test_data,glove_train_label,glove_test_label=train_test_split(glove_emails,labels,train_size=0.7,test_size=0.3,random_state=1654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9304851556842868\n",
      "TN: 792 FP: 43 FN: 53 TP: 493\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (93.05%)\n",
    "logreg_glove=LogisticRegression(random_state=55973,solver='liblinear')\n",
    "logreg_glove.fit(glove_train_data,glove_train_label)\n",
    "glove_test_pred=logreg_glove.predict(glove_test_data)\n",
    "print('Acc:',logreg_glove.score(glove_test_data,glove_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(glove_test_label,glove_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9304851556842868\n",
      "TN: 804 FP: 31 FN: 65 TP: 481\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (93.05%)\n",
    "rf_glove=RandomForestClassifier(random_state=55973,n_estimators=10)\n",
    "rf_glove.fit(glove_train_data,glove_train_label)\n",
    "glove_test_pred=rf_glove.predict(glove_test_data)\n",
    "print('Acc:',rf_glove.score(glove_test_data,glove_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(glove_test_label,glove_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8689355539464156\n",
      "TN: 794 FP: 41 FN: 140 TP: 406\n"
     ]
    }
   ],
   "source": [
    "# SVM (86.89%)\n",
    "svm_glove=SVC(random_state=55973,gamma='auto')\n",
    "svm_glove.fit(glove_train_data,glove_train_label)\n",
    "glove_test_pred=svm_glove.predict(glove_test_data)\n",
    "print('Acc:',svm_glove.score(glove_test_data,glove_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(glove_test_label,glove_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9058653149891384\n",
      "TN: 762 FP: 73 FN: 57 TP: 489\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree (90.59%)\n",
    "tree_glove=DecisionTreeClassifier(random_state=55973)\n",
    "tree_glove.fit(glove_train_data,glove_train_label)\n",
    "glove_test_pred=tree_glove.predict(glove_test_data)\n",
    "print('Acc:',tree_glove.score(glove_test_data,glove_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(glove_test_label,glove_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8957277335264301\n",
      "TN: 798 FP: 37 FN: 107 TP: 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emintatar/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# LDA (89.57%)\n",
    "lda_glove=LinearDiscriminantAnalysis()\n",
    "lda_glove.fit(glove_train_data,glove_train_label)\n",
    "glove_test_pred=lda_glove.predict(glove_test_data)\n",
    "print('Acc:',lda_glove.score(glove_test_data,glove_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(glove_test_label,glove_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove collinearity, we apply again PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=303)\n",
    "glove_emails_pca=pca.fit_transform(glove_emails)\n",
    "glove_train_data_pca,glove_test_data_pca,glove_train_label_pca,glove_test_label_pca=train_test_split(glove_emails_pca,labels,train_size=0.7,test_size=0.3,random_state=1654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9051412020275162\n",
      "TN: 796 FP: 39 FN: 92 TP: 454\n"
     ]
    }
   ],
   "source": [
    "# LDA with PCA (90.51%)\n",
    "lda_glove_pca=LinearDiscriminantAnalysis()\n",
    "lda_glove_pca.fit(glove_train_data_pca,glove_train_label_pca)\n",
    "glove_pca_test_pred=lda_glove_pca.predict(glove_test_data_pca)\n",
    "print('Acc:',lda_glove_pca.score(glove_test_data_pca,glove_test_label_pca))\n",
    "tn, fp, fn, tp=confusion_matrix(glove_test_label_pca,glove_pca_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8790731354091238\n",
      "TN: 744 FP: 91 FN: 76 TP: 470\n"
     ]
    }
   ],
   "source": [
    "# KNN (87.91%)\n",
    "knn_glove=KNeighborsClassifier()\n",
    "knn_glove.fit(glove_train_data,glove_train_label)\n",
    "glove_test_pred=knn_glove.predict(glove_test_data)\n",
    "print('Acc:',knn_glove.score(glove_test_data,glove_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(glove_test_label,glove_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText Pretrained Dataset\n",
    "Finally, we repeat the same procedure one last time with 2 million 300-dimensional word vectors trained by FastText on Common Crawl dataset [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading FastText pretrained \n",
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir='/mypath/FastText/yukleme', mode='w')\n",
    "with open('/mypath/FastText/crawl-300d-2M.vec', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)\n",
    "    \n",
    "vectors = bcolz.carray(vectors[2:].reshape((1999995,300)), rootdir='/mypath/FastText/yukleme', mode='w')\n",
    "vectors.flush()\n",
    "pickle.dump(words, open('/mypath/FastText/crawl-300d-2M.vec_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open('/mypath/FastText/crawl-300d-2M.vec_idx.pkl', 'wb'))\n",
    "\n",
    "\n",
    "fasttext_words = {w: vectors[word2idx[w]-1] for w in words[1:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the loaded vectors with the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_words['the'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in the case of dataset trained by GloVe, all atributes except the 3 about capital run have vector presentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset is now of the form (4601, 303)\n"
     ]
    }
   ],
   "source": [
    "email_fasttext_words=np.column_stack([fasttext_words['make'],fasttext_words['address'],fasttext_words['all'],fasttext_words['3d'],fasttext_words['our'],fasttext_words['over'],fasttext_words['remove'],fasttext_words['internet'],fasttext_words['order'],fasttext_words['mail'],fasttext_words['receive'],fasttext_words['will'],fasttext_words['people'],fasttext_words['report'],fasttext_words['addresses'],fasttext_words['free'],fasttext_words['business'],fasttext_words['email'],fasttext_words['you'],fasttext_words['credit'],fasttext_words['your'],fasttext_words['font'],fasttext_words['000'],fasttext_words['money'],fasttext_words['hp'],fasttext_words['hpl'],fasttext_words['george'],fasttext_words['650'],fasttext_words['lab'],fasttext_words['labs'],fasttext_words['telnet'],fasttext_words['857'],fasttext_words['data'],fasttext_words['415'],fasttext_words['85'],fasttext_words['technology'],fasttext_words['1999'],fasttext_words['parts'],fasttext_words['pm'],fasttext_words['direct'],fasttext_words['cs'],fasttext_words['meeting'],fasttext_words['original'],fasttext_words['project'],fasttext_words['re'],fasttext_words['edu'],fasttext_words['table'],fasttext_words['conference'],fasttext_words[';'],fasttext_words['('],fasttext_words['['],fasttext_words['!'],fasttext_words['$'],fasttext_words['#']])\n",
    "words_in_fasttext=['make','address','all','3d','our','over','remove','internet','order','mail','receive','will','people','report','addresses','free','business','email','you','credit','your','font','000','money','hp','hpl','george','650','lab','labs','telnet','857','data','415','85','technology','1999','parts','pm','direct','cs','meeting','original','project','re','edu','table','conference',';','(','[','!','$','#']\n",
    "\n",
    "email_fasttext_coef=np.delete(data_nolabel,[54,55,56],axis=1)\n",
    "email_fasttext_concat=np.delete(data_nolabel,np.arange(54),axis=1)\n",
    "email_fasttext_body=np.zeros([4601,300])\n",
    "for i in range(4601):\n",
    "\tfor j in range(len(words_in_fasttext)):\n",
    "\t\temail_fasttext_body[i,:]=email_fasttext_body[i,:]+email_fasttext_coef[i,j]*email_fasttext_words[:,j]\n",
    "\n",
    "fasttext_emails=np.append(email_fasttext_body,email_fasttext_concat,axis=1)\n",
    "print(\"the dataset is now of the form\",fasttext_emails.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_train_data,fasttext_test_data,fasttext_train_label,fasttext_test_label=train_test_split(fasttext_emails,labels,train_size=0.7,test_size=0.3,random_state=1654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9319333816075308\n",
      "TN: 793 FP: 42 FN: 52 TP: 494\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (93.19%)\n",
    "logreg_fasttext=LogisticRegression(random_state=55973,solver='liblinear')\n",
    "logreg_fasttext.fit(fasttext_train_data,fasttext_train_label)\n",
    "fasttext_test_pred=logreg_fasttext.predict(fasttext_test_data)\n",
    "print('Acc:',logreg_fasttext.score(fasttext_test_data,fasttext_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(fasttext_test_label,fasttext_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.946415640839971\n",
      "TN: 809 FP: 26 FN: 48 TP: 498\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (94.64%)\n",
    "rf_fasttext=RandomForestClassifier(random_state=55973,n_estimators=10)\n",
    "rf_fasttext.fit(fasttext_train_data,fasttext_train_label)\n",
    "fasttext_test_pred=rf_fasttext.predict(fasttext_test_data)\n",
    "print('Acc:',rf_fasttext.score(fasttext_test_data,fasttext_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(fasttext_test_label,fasttext_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.889210716871832\n",
      "TN: 744 FP: 91 FN: 62 TP: 484\n"
     ]
    }
   ],
   "source": [
    "# SVM (88.92%)\n",
    "svm_fasttext=SVC(random_state=55973,gamma='auto')\n",
    "svm_fasttext.fit(fasttext_train_data,fasttext_train_label)\n",
    "fasttext_test_pred=svm_fasttext.predict(fasttext_test_data)\n",
    "print('Acc:',svm_fasttext.score(fasttext_test_data,fasttext_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(fasttext_test_label,fasttext_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9087617668356264\n",
      "TN: 766 FP: 69 FN: 57 TP: 489\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree (90.88%)\n",
    "tree_fasttext=DecisionTreeClassifier(random_state=55973)\n",
    "tree_fasttext.fit(fasttext_train_data,fasttext_train_label)\n",
    "fasttext_test_pred=tree_fasttext.predict(fasttext_test_data)\n",
    "print('Acc:',tree_fasttext.score(fasttext_test_data,fasttext_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(fasttext_test_label,fasttext_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8957277335264301\n",
      "TN: 798 FP: 37 FN: 107 TP: 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emintatar/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# LDA (89.57%)\n",
    "lda_fasttext=LinearDiscriminantAnalysis()\n",
    "lda_fasttext.fit(fasttext_train_data,fasttext_train_label)\n",
    "fasttext_test_pred=lda_fasttext.predict(fasttext_test_data)\n",
    "print('Acc:',lda_fasttext.score(fasttext_test_data,fasttext_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(fasttext_test_label,fasttext_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA to remove collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=303)\n",
    "fasttext_emails_pca=pca.fit_transform(fasttext_emails)\n",
    "fasttext_train_data_pca,fasttext_test_data_pca,fasttext_train_label_pca,fasttext_test_label_pca=train_test_split(fasttext_emails_pca,labels,train_size=0.7,test_size=0.3,random_state=1654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9000724112961622\n",
      "TN: 799 FP: 36 FN: 102 TP: 444\n"
     ]
    }
   ],
   "source": [
    "# LDA with PCA (90%)\n",
    "lda_fasttext_pca=LinearDiscriminantAnalysis()\n",
    "lda_fasttext_pca.fit(fasttext_train_data_pca,fasttext_train_label_pca)\n",
    "fasttext_pca_test_pred=lda_fasttext_pca.predict(fasttext_test_data_pca)\n",
    "print('Acc:',lda_fasttext_pca.score(fasttext_test_data_pca,fasttext_test_label_pca))\n",
    "tn, fp, fn, tp=confusion_matrix(fasttext_test_label_pca,fasttext_pca_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8515568428674873\n",
      "TN: 723 FP: 112 FN: 93 TP: 453\n"
     ]
    }
   ],
   "source": [
    "# KNN (85.16%)\n",
    "knn_fasttext=KNeighborsClassifier()\n",
    "knn_fasttext.fit(fasttext_train_data,fasttext_train_label)\n",
    "fasttext_test_pred=knn_fasttext.predict(fasttext_test_data)\n",
    "print('Acc:',knn_fasttext.score(fasttext_test_data,fasttext_test_label))\n",
    "tn, fp, fn, tp=confusion_matrix(fasttext_test_label,fasttext_test_pred).ravel()\n",
    "print('TN:',tn,'FP:',fp,'FN:',fn,'TP:',tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({'Classifier':['LogReg','RandForest','SVM','D.Tree','PCA+LDA','KNN'],'Original':[logreg.score(test_data,test_label),rf.score(test_data,test_label),svm.score(test_data,test_label),tree.score(test_data,test_label),lda.score(test_data,test_label),knn.score(test_data,test_label)],'Word2Vec':[logreg_w2v.score(w2v_test_data,w2v_test_label),rf_w2v.score(w2v_test_data,w2v_test_label),svm_w2v.score(w2v_test_data,w2v_test_label),tree_w2v.score(w2v_test_data,w2v_test_label),lda_w2v_pca.score(w2v_test_data_pca,w2v_test_label_pca),knn_w2v.score(w2v_test_data,w2v_test_label)],'Glove':[logreg_glove.score(glove_test_data,glove_test_label),rf_glove.score(glove_test_data,glove_test_label),svm_glove.score(glove_test_data,glove_test_label),tree_glove.score(glove_test_data,glove_test_label),lda_glove_pca.score(glove_test_data_pca,glove_test_label_pca),knn_glove.score(glove_test_data,glove_test_label)],'FastText':[logreg_fasttext.score(fasttext_test_data,fasttext_test_label),rf_fasttext.score(fasttext_test_data,fasttext_test_label),svm_fasttext.score(fasttext_test_data,fasttext_test_label),tree_fasttext.score(fasttext_test_data,fasttext_test_label),lda_fasttext_pca.score(fasttext_test_data_pca,fasttext_test_label_pca),knn_fasttext.score(fasttext_test_data,fasttext_test_label)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Original</th>\n",
       "      <th>Word2Vec</th>\n",
       "      <th>Glove</th>\n",
       "      <th>FastText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.929037</td>\n",
       "      <td>0.929761</td>\n",
       "      <td>0.930485</td>\n",
       "      <td>0.931933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandForest</td>\n",
       "      <td>0.960174</td>\n",
       "      <td>0.934830</td>\n",
       "      <td>0.930485</td>\n",
       "      <td>0.946416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.834902</td>\n",
       "      <td>0.874004</td>\n",
       "      <td>0.868936</td>\n",
       "      <td>0.889211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D.Tree</td>\n",
       "      <td>0.916727</td>\n",
       "      <td>0.905865</td>\n",
       "      <td>0.905865</td>\n",
       "      <td>0.908762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA+LDA</td>\n",
       "      <td>0.895728</td>\n",
       "      <td>0.897176</td>\n",
       "      <td>0.905141</td>\n",
       "      <td>0.900072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.795076</td>\n",
       "      <td>0.838523</td>\n",
       "      <td>0.879073</td>\n",
       "      <td>0.851557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier  Original  Word2Vec     Glove  FastText\n",
       "0      LogReg  0.929037  0.929761  0.930485  0.931933\n",
       "1  RandForest  0.960174  0.934830  0.930485  0.946416\n",
       "2         SVM  0.834902  0.874004  0.868936  0.889211\n",
       "3      D.Tree  0.916727  0.905865  0.905865  0.908762\n",
       "4     PCA+LDA  0.895728  0.897176  0.905141  0.900072\n",
       "5         KNN  0.795076  0.838523  0.879073  0.851557"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "results.plot(ax=ax,xticks=results.index,rot=45)\n",
    "ax.set_xticklabels(results['Classifier'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that embedding the dataset into higher dimensions gives slight advantage when linear classifiers are used and significant advantage when KNeighborhood classifier is used. On the other hand, the original form of the dataset clearly performs better when tree-based classifiers are used, something tht will be investigated in the further posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refenrences\n",
    "1) Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.\n",
    "\n",
    "2) Jeffrey Pennington, Richard Socher, and Christopher D. Manning. Glove: Global vectors for word representation. In Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, 2014.\n",
    "\n",
    "3) Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. Bag of tricks for efficient text classification. arXiv preprint arXiv:1607.01759, 2016."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
